# -*- coding: utf-8 -*-
"""Q2(iv)_right.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16YRODXjRFlXWR5WPwqMhMAU8g3ljlSIN
"""

#Importing required modules
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sys
import random
from sklearn.model_selection import train_test_split

#Extracting data from the given csv files
train_data = pd.read_csv('A2Q2Data_train.csv', header=None, index_col=False)
test_data = pd.read_csv('A2Q2Data_test.csv', header=None, index_col=False)
a = np.array(train_data)
t = np.array(test_data)

#Extracting all X values from training dataset
rows,cols = (len(a),(len(a[0])-1))

X = []
for i in range(rows):
  col = []
  for j in range(cols):
    col.append(0)
  X.append(col)

#Extracting all y values from training dataset

rowsy,colsy = (len(a),1)
y = []
for i in range(rowsy):
  coly = []
  for j in range(colsy):
    coly.append(0)
  y.append(coly)

for i in range(len(X)):
  for j in range(len(X[0])):
    X[i][j] = a[i][j]

for i in range(len(a)):
  y[i][0] = a[i][100]

y = np.array(y)

#Finding y transpose
yt = y.transpose()

#Converting X to array from list of lists
X = np.array(X)

#Finding X transpose
Xt = X.transpose()

#Applying ((XtX)^-1)(Xty) to find w^ml
C = np.dot(Xt,X)

Ci = np.linalg.inv(C)

#w^ml calculated
w = np.dot(np.dot(Ci,Xt),y)

#Running the Gradient descent with values of lambda ranging from 1 to 30
Wit = []
for i in range(30):
  Lambda = (i+1)
  #Cross validation using 80:20 splitting
  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)
  it = 1
  wt = []
  for i in range(100):
    wt.append(1)

  wt = np.array(wt)
  wt = wt.reshape((len(wt),1))

  #Applying gradient descent
  while(it<=3000):
    step = 0.000005
    P = np.dot(X_train.T,X_train)
    S=np.dot(P,wt)
    Q=np.dot(X_train.T,y_train)
    ridge = Lambda*wt
    R = S-Q+ridge
    wt = np.subtract(wt,step*R)

    it+=1
  Wit.append(wt)

#Finding error for the various w's obtained from different values of lambdas
iter = []
Ypred = []
print(len(Wit))
for i in range(30):
  Ypred.append(np.linalg.norm(np.matmul(X_test,Wit[i]) - y_test)**2)
  iter.append((i+1))

#Plotting errors for the various w's obtained from different values of lambda
g = plt.figure(1)
plt.xlabel('x-axis - Lambda')
plt.ylabel('y-axis - Error')
plt.title("Error vs Lambda",color='black')
plt.grid()
plt.plot(iter,Ypred)

plt.show()

#Extracting all X values from testing dataset
rows,cols = (len(t),(len(t[0])-1))

T = []
for i in range(rows):
  col = []
  for j in range(cols):
    col.append(0)
  T.append(col)

#Extracting all y values from testing dataset
rowsy,colsy = (len(t),1)
yte = []
for i in range(rowsy):
  coly = []
  for j in range(colsy):
    coly.append(0)
  yte.append(coly)

for i in range(len(T)):
  for j in range(len(T[0])):
    T[i][j] = t[i][j]

for i in range(len(t)):
  yte[i][0] = t[i][100]

#Printing MSE for w^ml and wr for test dataset
sum2 = 0
err = (np.linalg.norm(np.dot(T,w)-yte)**2)
print("MSE through w^ml",err)

error = (np.linalg.norm(np.dot(T,Wit[17])-yte)**2)
print("MSE through wr",error)