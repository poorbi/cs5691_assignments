# -*- coding: utf-8 -*-
"""Q2(ii).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BcbRq8bPHTa-cs8kzdP_lghGGxmjfZcE
"""

#Importing required modules
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sys
import random

#Extracting data from the given csv files
train_data = pd.read_csv('A2Q2Data_train.csv', header=None, index_col=False)
test_data = pd.read_csv('A2Q2Data_test.csv', header=None, index_col=False)
a = np.array(train_data)
t = np.array(test_data)

#Extracting all X values from training dataset
rows,cols = (len(a),(len(a[0])-1))

X = []
for i in range(rows):
  col = []
  for j in range(cols):
    col.append(0)
  X.append(col)

#Extracting all y values from training dataset

rowsy,colsy = (len(a),1)
y = []
for i in range(rowsy):
  coly = []
  for j in range(colsy):
    coly.append(0)
  y.append(coly)

for i in range(len(X)):
  for j in range(len(X[0])):
    X[i][j] = a[i][j]

for i in range(len(a)):
  y[i][0] = a[i][100]

y = np.array(y)

#Finding y transpose
yt = y.transpose()

#Converting X to array from list of lists
X = np.array(X)

#Finding X transpose
Xt = X.transpose()

#Applying ((XtX)^-1)(Xty) to find w^ml
C = np.dot(Xt,X)

Ci = np.linalg.inv(C)

#w^ml calculated
w = np.dot(np.dot(Ci,Xt),y)

#Apply gradient descent
it = 1

wt = []
error = []
iter=[]
for i in range(len(w)):
  wt.append(1)

wt = np.array(wt)
wt = wt.reshape((len(wt),1))

while(it<=9000):
  step = 0.00001
  yp = np.dot(X,wt)
  P = 2 * step * np.dot(Xt,np.subtract(yp,y))/10000
  wt = np.subtract(wt,P)
  
  error.append(np.linalg.norm(wt-w,2))
  iter.append(it)

  it+=1

#Plotting || wt - w^ml ||2 vs t
g = plt.figure(1)
plt.xlabel('x-axis - t')
plt.ylabel('y-axis - || wt - w^ml ||2')
plt.title("|| wt - w^ml ||2 vs t",color='black')
plt.grid()
plt.plot(iter,error)

plt.show()